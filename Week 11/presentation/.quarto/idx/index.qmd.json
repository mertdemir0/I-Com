{"title":"Sentiment Analysis with Python","markdown":{"yaml":{"title":"Sentiment Analysis with Python","authors":[{"name":"Mert Demir","affiliation":"Fondazione Eni Enrico Mattei","roles":"Research Data Scientist","corresponding":true}],"bibliography":"references.bib"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nToday, we'll explore an advanced Python script that performs news sentiment analysis and aggregation from RSS feeds. We'll cover asynchronous programming, natural language processing, database operations, and task scheduling.\n\n## Introduction to Key Concepts\n\n### Asynchronous Programming\n\nAsynchronous programming is a programming paradigm that allows multiple operations to be executed concurrently without blocking the main thread of execution. In Python, this is primarily achieved using the `asyncio` module and the `async/await` syntax.\n\nKey benefits of asynchronous programming include:\n\n1.  Improved performance for I/O-bound tasks\n2.  Better resource utilization\n3.  Enhanced scalability for applications handling many concurrent operations\n\nIn our script, we use asynchronous programming to efficiently fetch data from multiple RSS feeds simultaneously, significantly reducing the overall execution time compared to a synchronous approach.\n\n### Large Language Models (LLMs)\n\nLarge Language Models are advanced AI models trained on vast amounts of text data. They can understand and generate human-like text, and perform various natural language processing tasks such as sentiment analysis, text classification, and language translation.\n\nSome key characteristics of LLMs include:\n\n1.  **Massive scale:** Trained on billions of parameters\n2.  **Versatility:** Can be fine-tuned for specific tasks\n3.  **Context understanding:** Can comprehend nuanced language use\n\nIn our script, we use a pre-trained BERT (Bidirectional Encoder Representations from Transformers) model, which is a type of LLM. Specifically, we're using an Italian BERT model for sentiment analysis of Italian news articles.\n\nWe're using an LLM for this task because:\n\n1.  **Accuracy:** LLMs can capture subtle nuances in language, leading to more accurate sentiment analysis.\n2.  **Efficiency:** Pre-trained models can be quickly adapted to our specific use case without extensive training.\n3.  **Multilingual capability:** We can easily switch to models for different languages if needed.\n\n## Install\n\n``` {.python .Python}\npip install asyncio aiohttp feedparser pandas transformers torch apscheduler\n```\n\n## Import Statements\n\n``` python\nimport asyncio # framework for writing asynchronous code\nimport aiohttp # an asynchronous HTTP client/server framework for asyncio\nimport feedparser # for parsing RSS\nimport csv\nimport sqlite3 # working with SQLite databases\nfrom datetime import datetime\nfrom urllib.parse import urlparse #to parse URLs into their components\nimport pandas as pd\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n# provides pre-trained models for natural language processing tasks\nimport torch # used for machine learning tasks\nfrom apscheduler.schedulers.asyncio import AsyncIOScheduler\n# used for scheduling tasks asynchronously\nimport logging\n```\n\n> -   `AutoModelForSequenceClassification`: Automatically loads a pre-trained model for sequence classification tasks.\n>\n> <!-- -->\n>\n> -   `AutoTokenizer`: Automatically loads the appropriate tokenizer for a given model.\n\n``` python\n# Set up logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n```\n\n## Model Initiliazation\n\n``` python\n# Initialize BERT model and tokenizer\nmodel_name = \"dbmdz/bert-base-italian-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\n```\n\n> -   `model_name`: a pre-trained Italian BERT model.\n>\n> <!-- -->\n>\n> -   `AutoTokenizer`: Automatically loads the appropriate tokenizer for the model. Tokenizers convert text into a format the model can understand.\n>\n> <!-- -->\n>\n> -   `AutoModelForSequenceClassification`: Loads the pre-trained model for sentiment classification. This class automatically configures the model for sequence classification tasks.\n\n![](images/1_CdjbU3J5BYuIi-4WbWnKng.png){fig-align=\"center\" width=\"565\"}\n\n> We use these because they provide a convenient way to use NLP models without training from scratch.\n\n## Data Sources and Keywords\n\n``` python\nRSS_SOURCES = [\n    \"https://www.repubblica.it/rss/homepage/rss2.0.xml\",\n    \"https://www.corriere.it/rss/homepage.xml\",\n    # Now we will find RSS feeds\n]\n# You can adjust the keywords for the topics you wanna perform sentiment analysis.\nKEYWORDS = [\"economia\", \"politica\", \"tecnologia\", \"salute\", \"nucleare\", \"covid\"]\n```\n\n``` python\n# This set will store processed article links to avoid duplicates.\nprocessed_links = set()\n```\n\n## Sentiment Analysis Function\n\n``` python\ndef analyze_sentiment(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    logits = outputs.logits\n    probabilities = torch.softmax(logits, dim=1)\n    sentiment_score = probabilities[0, 1].item() - probabilities[0, 0].item()  # Positive - Negative\n    \n    return sentiment_score\n```\n\n> -   `text`: The input text to tokenize.\n>\n> <!-- -->\n>\n> -   `return_tensors=\"pt\"`: Returns PyTorch tensors.\n>\n> <!-- -->\n>\n> -   `truncation=True`: Truncates text longer than the model's maximum input length.\n>\n> <!-- -->\n>\n> -   `max_length=512`: Sets the maximum length of the input.\n>\n> <!-- -->\n>\n> -   `padding=True`: Pads shorter sequences to the maximum length.\n\n> **Calculating Sentiment Score:**\n>\n> `sentiment_score` calculates the sentiment score by subtracting the negative sentiment probability from the positive sentiment probability.\n\n## Keyword Search Function\n\n``` python\ndef search_keywords(text):\n    text_lower = text.lower()\n    return [keyword for keyword in KEYWORDS if keyword in text_lower]\n```\n\n> comprehension returns all keywords found in the lowercase text\n\n## Asynchronous News Fetching Function\n\n``` python\nasync def fetch_news_async(rss_url):\n    async with aiohttp.ClientSession() as session:\n        async with session.get(rss_url) as response:\n            content = await response.text()\n            return feedparser.parse(content)\n```\n\n## Website Name Extraction Function\n\n``` python\ndef get_website_name(url):\n    parsed_url = urlparse(url)\n    return parsed_url.netloc # returns the network location (domain) part of the URL\n```\n\n## Main Processing Function\n\n``` python\nasync def process_feeds():\n    results = [] # empty list to store the results\n    for source in RSS_SOURCES:\n        feed = await fetch_news_async(source)\n        if feed:\n            for item in feed.entries:\n                link = item.get('link', '')\n                if link not in processed_links: # checks if the link has already been processed\n                    full_text = item.get('title', '') + ' ' + item.get('summary', '')\n                    sentiment = analyze_sentiment(full_text)\n                    matched_keywords = search_keywords(full_text)\n                    results.append({\n                        'title': item.get('title', ''),\n                        'full_text': full_text,\n                        'link': link,\n                        'source': get_website_name(source),\n                        'sentiment': sentiment,\n                        'pub_date': item.get('published', ''),\n                        'author': item.get('author', ''),\n                        'keywords': ', '.join(matched_keywords)\n                    })\n                    processed_links.add(link)\n    return results\n```\n\n## CSV Saving Function\n\n``` python\ndef save_to_csv(data, filename='news_sentiment.csv'):\n    with open(filename, 'a', newline='', encoding='utf-8') as file: # 'a' for append mode\n        writer = csv.DictWriter(file, fieldnames=data[0].keys())\n        if file.tell() == 0:\n            writer.writeheader()\n        writer.writerows(data)\n```\n\n## Database Saving Function\n\n``` python\ndef save_to_database(data, db_name='news_sentiment.db'):\n    conn = sqlite3.connect(db_name)\n    df = pd.DataFrame(data)\n    df.to_sql('news', conn, if_exists='append', index=False)\n    conn.close()\n```\n\n## Main Execution Function\n\n``` python\nasync def main():\n    results = await process_feeds()\n    if results:\n        save_to_csv(results)\n        save_to_database(results)\n        logging.info(f\"Processed {len(results)} new news items.\")\n    else:\n        logging.info(\"No new news items to process.\")\n```\n\n## Scheduled Job Function\n\n``` python\ndef scheduled_job():\n    asyncio.run(main())\n```\n\n## Main Execution Block\n\n``` python\nif __name__ == \"__main__\":\n    # Run the job immediately\n    scheduled_job()\n    \n    # Set up the scheduler\n    scheduler = AsyncIOScheduler()\n    scheduler.add_job(scheduled_job, 'interval', hours=1) # you can change the hour\n    scheduler.start()\n    logging.info(\"Scheduler started. Press Ctrl+C to exit.\")\n\n    try:\n        asyncio.get_event_loop().run_forever()\n    except (KeyboardInterrupt, SystemExit):\n        pass\n```\n\n![](images/istockphoto-1345220254-612x612.jpg){fig-align=\"left\"}\n\n## To-Do\n\n-   Implement error handling and retries for RSS feed fetching\n    -   Add a retry mechanism for failed HTTP requests\n\n    -   Implement exponential backoff for repeated failures\n\n<!-- -->\n\n-   Enhance the sentiment analysis model\n    -   Consider fine-tuning the BERT model on domain-specific data\n\n    -   Implement a more nuanced sentiment scale (e.g., very negative, negative, neutral, positive, very positive)\n\n<!-- -->\n\n-   Improve topic modeling\n    -   Experiment with different numbers of topics for the NMF mode\n\n    -   Implement dynamic topic modeling to adapt to changing news trends\n\n    -   Consider using more advanced topic modeling techniques like LDA (Latent Dirichlet Allocation)\n\n<!-- -->\n\n-   Optimize database operations\n    -   Implement batch inserts for better performance\n\n    -   Add indexes to frequently queried columns\n\n    -   Consider using an ORM like SQLAlchemy for better database management\n\n<!-- -->\n\n-   Enhance the dashboard\n    -   Add more visualizations (e.g., word clouds, topic distribution pie charts)\n\n    -   Implement user authentication for the dashboard\n\n    -   Add the ability to export data in various formats (CSV, JSON, etc.)\n\n<!-- -->\n\n-   Implement caching\n    -   Use a caching mechanism (e.g., Redis) to store frequently accessed data and reduce database load\n\n<!-- -->\n\n-   Add more data sources\n    -   Integrate with news APIs for a broader range of sources\n\n    -   Implement web scraping for sources without RSS feeds\n\n<!-- -->\n\n-   Improve logging and monitoring\n    -   Implement more detailed logging for better debugging\n\n    -   Add system monitoring (e.g., CPU usage, memory usage, database performance)\n\n<!-- -->\n\n-   Enhance configurability\n    -   Make more parameters configurable through the config file\n\n    -   Implement a web interface for changing configuration settings\n\n<!-- -->\n\n-   Implement data cleaning and preprocessing\n\n    -   Add text cleaning functions (e.g., removing HTML tags, handling special characters)\n\n    -   Implement language detection to filter out non-Italian content\n\n<!-- -->\n\n-   Add unit tests and integration tests\n\n    -   Write unit tests for individual functions\n\n    -   Implement integration tests for the entire pipeline\n\n<!-- -->\n\n-   Optimize performance\n\n    -   Profile the code to identify bottlenecks\n\n    -   Implement multiprocessing for CPU-bound tasks\n\n<!-- -->\n\n-   Implement data retention policies\n\n    -   Add functionality to archive or delete old news items\n\n    -   Implement data compression for long-term storage\n\n<!-- -->\n\n-   Enhance specific topic detection\n\n    -   Implement machine learning-based classification for specific topics\n    -   Allow users to define and train custom topics\n\n<!-- -->\n\n-   Add trend detection\n\n    -   Implement algorithms to detect sudden changes in sentiment or topic popularity\n    -   Add alerts for significant trend changes","srcMarkdownNoYaml":"\n\n## Introduction\n\nToday, we'll explore an advanced Python script that performs news sentiment analysis and aggregation from RSS feeds. We'll cover asynchronous programming, natural language processing, database operations, and task scheduling.\n\n## Introduction to Key Concepts\n\n### Asynchronous Programming\n\nAsynchronous programming is a programming paradigm that allows multiple operations to be executed concurrently without blocking the main thread of execution. In Python, this is primarily achieved using the `asyncio` module and the `async/await` syntax.\n\nKey benefits of asynchronous programming include:\n\n1.  Improved performance for I/O-bound tasks\n2.  Better resource utilization\n3.  Enhanced scalability for applications handling many concurrent operations\n\nIn our script, we use asynchronous programming to efficiently fetch data from multiple RSS feeds simultaneously, significantly reducing the overall execution time compared to a synchronous approach.\n\n### Large Language Models (LLMs)\n\nLarge Language Models are advanced AI models trained on vast amounts of text data. They can understand and generate human-like text, and perform various natural language processing tasks such as sentiment analysis, text classification, and language translation.\n\nSome key characteristics of LLMs include:\n\n1.  **Massive scale:** Trained on billions of parameters\n2.  **Versatility:** Can be fine-tuned for specific tasks\n3.  **Context understanding:** Can comprehend nuanced language use\n\nIn our script, we use a pre-trained BERT (Bidirectional Encoder Representations from Transformers) model, which is a type of LLM. Specifically, we're using an Italian BERT model for sentiment analysis of Italian news articles.\n\nWe're using an LLM for this task because:\n\n1.  **Accuracy:** LLMs can capture subtle nuances in language, leading to more accurate sentiment analysis.\n2.  **Efficiency:** Pre-trained models can be quickly adapted to our specific use case without extensive training.\n3.  **Multilingual capability:** We can easily switch to models for different languages if needed.\n\n## Install\n\n``` {.python .Python}\npip install asyncio aiohttp feedparser pandas transformers torch apscheduler\n```\n\n## Import Statements\n\n``` python\nimport asyncio # framework for writing asynchronous code\nimport aiohttp # an asynchronous HTTP client/server framework for asyncio\nimport feedparser # for parsing RSS\nimport csv\nimport sqlite3 # working with SQLite databases\nfrom datetime import datetime\nfrom urllib.parse import urlparse #to parse URLs into their components\nimport pandas as pd\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n# provides pre-trained models for natural language processing tasks\nimport torch # used for machine learning tasks\nfrom apscheduler.schedulers.asyncio import AsyncIOScheduler\n# used for scheduling tasks asynchronously\nimport logging\n```\n\n> -   `AutoModelForSequenceClassification`: Automatically loads a pre-trained model for sequence classification tasks.\n>\n> <!-- -->\n>\n> -   `AutoTokenizer`: Automatically loads the appropriate tokenizer for a given model.\n\n``` python\n# Set up logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n```\n\n## Model Initiliazation\n\n``` python\n# Initialize BERT model and tokenizer\nmodel_name = \"dbmdz/bert-base-italian-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\n```\n\n> -   `model_name`: a pre-trained Italian BERT model.\n>\n> <!-- -->\n>\n> -   `AutoTokenizer`: Automatically loads the appropriate tokenizer for the model. Tokenizers convert text into a format the model can understand.\n>\n> <!-- -->\n>\n> -   `AutoModelForSequenceClassification`: Loads the pre-trained model for sentiment classification. This class automatically configures the model for sequence classification tasks.\n\n![](images/1_CdjbU3J5BYuIi-4WbWnKng.png){fig-align=\"center\" width=\"565\"}\n\n> We use these because they provide a convenient way to use NLP models without training from scratch.\n\n## Data Sources and Keywords\n\n``` python\nRSS_SOURCES = [\n    \"https://www.repubblica.it/rss/homepage/rss2.0.xml\",\n    \"https://www.corriere.it/rss/homepage.xml\",\n    # Now we will find RSS feeds\n]\n# You can adjust the keywords for the topics you wanna perform sentiment analysis.\nKEYWORDS = [\"economia\", \"politica\", \"tecnologia\", \"salute\", \"nucleare\", \"covid\"]\n```\n\n``` python\n# This set will store processed article links to avoid duplicates.\nprocessed_links = set()\n```\n\n## Sentiment Analysis Function\n\n``` python\ndef analyze_sentiment(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    logits = outputs.logits\n    probabilities = torch.softmax(logits, dim=1)\n    sentiment_score = probabilities[0, 1].item() - probabilities[0, 0].item()  # Positive - Negative\n    \n    return sentiment_score\n```\n\n> -   `text`: The input text to tokenize.\n>\n> <!-- -->\n>\n> -   `return_tensors=\"pt\"`: Returns PyTorch tensors.\n>\n> <!-- -->\n>\n> -   `truncation=True`: Truncates text longer than the model's maximum input length.\n>\n> <!-- -->\n>\n> -   `max_length=512`: Sets the maximum length of the input.\n>\n> <!-- -->\n>\n> -   `padding=True`: Pads shorter sequences to the maximum length.\n\n> **Calculating Sentiment Score:**\n>\n> `sentiment_score` calculates the sentiment score by subtracting the negative sentiment probability from the positive sentiment probability.\n\n## Keyword Search Function\n\n``` python\ndef search_keywords(text):\n    text_lower = text.lower()\n    return [keyword for keyword in KEYWORDS if keyword in text_lower]\n```\n\n> comprehension returns all keywords found in the lowercase text\n\n## Asynchronous News Fetching Function\n\n``` python\nasync def fetch_news_async(rss_url):\n    async with aiohttp.ClientSession() as session:\n        async with session.get(rss_url) as response:\n            content = await response.text()\n            return feedparser.parse(content)\n```\n\n## Website Name Extraction Function\n\n``` python\ndef get_website_name(url):\n    parsed_url = urlparse(url)\n    return parsed_url.netloc # returns the network location (domain) part of the URL\n```\n\n## Main Processing Function\n\n``` python\nasync def process_feeds():\n    results = [] # empty list to store the results\n    for source in RSS_SOURCES:\n        feed = await fetch_news_async(source)\n        if feed:\n            for item in feed.entries:\n                link = item.get('link', '')\n                if link not in processed_links: # checks if the link has already been processed\n                    full_text = item.get('title', '') + ' ' + item.get('summary', '')\n                    sentiment = analyze_sentiment(full_text)\n                    matched_keywords = search_keywords(full_text)\n                    results.append({\n                        'title': item.get('title', ''),\n                        'full_text': full_text,\n                        'link': link,\n                        'source': get_website_name(source),\n                        'sentiment': sentiment,\n                        'pub_date': item.get('published', ''),\n                        'author': item.get('author', ''),\n                        'keywords': ', '.join(matched_keywords)\n                    })\n                    processed_links.add(link)\n    return results\n```\n\n## CSV Saving Function\n\n``` python\ndef save_to_csv(data, filename='news_sentiment.csv'):\n    with open(filename, 'a', newline='', encoding='utf-8') as file: # 'a' for append mode\n        writer = csv.DictWriter(file, fieldnames=data[0].keys())\n        if file.tell() == 0:\n            writer.writeheader()\n        writer.writerows(data)\n```\n\n## Database Saving Function\n\n``` python\ndef save_to_database(data, db_name='news_sentiment.db'):\n    conn = sqlite3.connect(db_name)\n    df = pd.DataFrame(data)\n    df.to_sql('news', conn, if_exists='append', index=False)\n    conn.close()\n```\n\n## Main Execution Function\n\n``` python\nasync def main():\n    results = await process_feeds()\n    if results:\n        save_to_csv(results)\n        save_to_database(results)\n        logging.info(f\"Processed {len(results)} new news items.\")\n    else:\n        logging.info(\"No new news items to process.\")\n```\n\n## Scheduled Job Function\n\n``` python\ndef scheduled_job():\n    asyncio.run(main())\n```\n\n## Main Execution Block\n\n``` python\nif __name__ == \"__main__\":\n    # Run the job immediately\n    scheduled_job()\n    \n    # Set up the scheduler\n    scheduler = AsyncIOScheduler()\n    scheduler.add_job(scheduled_job, 'interval', hours=1) # you can change the hour\n    scheduler.start()\n    logging.info(\"Scheduler started. Press Ctrl+C to exit.\")\n\n    try:\n        asyncio.get_event_loop().run_forever()\n    except (KeyboardInterrupt, SystemExit):\n        pass\n```\n\n![](images/istockphoto-1345220254-612x612.jpg){fig-align=\"left\"}\n\n## To-Do\n\n-   Implement error handling and retries for RSS feed fetching\n    -   Add a retry mechanism for failed HTTP requests\n\n    -   Implement exponential backoff for repeated failures\n\n<!-- -->\n\n-   Enhance the sentiment analysis model\n    -   Consider fine-tuning the BERT model on domain-specific data\n\n    -   Implement a more nuanced sentiment scale (e.g., very negative, negative, neutral, positive, very positive)\n\n<!-- -->\n\n-   Improve topic modeling\n    -   Experiment with different numbers of topics for the NMF mode\n\n    -   Implement dynamic topic modeling to adapt to changing news trends\n\n    -   Consider using more advanced topic modeling techniques like LDA (Latent Dirichlet Allocation)\n\n<!-- -->\n\n-   Optimize database operations\n    -   Implement batch inserts for better performance\n\n    -   Add indexes to frequently queried columns\n\n    -   Consider using an ORM like SQLAlchemy for better database management\n\n<!-- -->\n\n-   Enhance the dashboard\n    -   Add more visualizations (e.g., word clouds, topic distribution pie charts)\n\n    -   Implement user authentication for the dashboard\n\n    -   Add the ability to export data in various formats (CSV, JSON, etc.)\n\n<!-- -->\n\n-   Implement caching\n    -   Use a caching mechanism (e.g., Redis) to store frequently accessed data and reduce database load\n\n<!-- -->\n\n-   Add more data sources\n    -   Integrate with news APIs for a broader range of sources\n\n    -   Implement web scraping for sources without RSS feeds\n\n<!-- -->\n\n-   Improve logging and monitoring\n    -   Implement more detailed logging for better debugging\n\n    -   Add system monitoring (e.g., CPU usage, memory usage, database performance)\n\n<!-- -->\n\n-   Enhance configurability\n    -   Make more parameters configurable through the config file\n\n    -   Implement a web interface for changing configuration settings\n\n<!-- -->\n\n-   Implement data cleaning and preprocessing\n\n    -   Add text cleaning functions (e.g., removing HTML tags, handling special characters)\n\n    -   Implement language detection to filter out non-Italian content\n\n<!-- -->\n\n-   Add unit tests and integration tests\n\n    -   Write unit tests for individual functions\n\n    -   Implement integration tests for the entire pipeline\n\n<!-- -->\n\n-   Optimize performance\n\n    -   Profile the code to identify bottlenecks\n\n    -   Implement multiprocessing for CPU-bound tasks\n\n<!-- -->\n\n-   Implement data retention policies\n\n    -   Add functionality to archive or delete old news items\n\n    -   Implement data compression for long-term storage\n\n<!-- -->\n\n-   Enhance specific topic detection\n\n    -   Implement machine learning-based classification for specific topics\n    -   Allow users to define and train custom topics\n\n<!-- -->\n\n-   Add trend detection\n\n    -   Implement algorithms to detect sudden changes in sentiment or topic popularity\n    -   Add alerts for significant trend changes"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":true,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":[{"text":"MECA Bundle","href":"index-meca.zip","icon":"archive","attr":{"data-meca-link":"true"},"order":1000}],"notebook-preserve-cells":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.53","manuscript":{"article":"index.qmd","notebooks":[],"mecaFile":"index-meca.zip"},"quarto-internal":{"subarticles":[]},"notebook-preview-options":{"back":true},"theme":"cosmo","title-block-style":"manuscript","lightbox":"auto","comments":{"hypothesis":true},"title":"Sentiment Analysis with Python","authors":[{"name":"Mert Demir","affiliation":"Fondazione Eni Enrico Mattei","roles":"Research Data Scientist","corresponding":true}],"bibliography":["references.bib"],"google-scholar":true,"toc-location":"left","clear-hidden-classes":"none","remove-hidden":"all","unroll-markdown-cells":true},"extensions":{"book":{"multiFile":true}}},"docx":{"identifier":{"display-name":"MS Word","target-format":"docx","base-format":"docx"},"execute":{"fig-width":5,"fig-height":4,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":true,"prefer-html":false,"output-divs":true,"output-ext":"docx","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"page-width":6.5,"format-links":[{"text":"MECA Bundle","href":"index-meca.zip","icon":"archive","attr":{"data-meca-link":"true"},"order":1000}],"notebook-preserve-cells":true},"pandoc":{"default-image-extension":"png","to":"docx","output-file":"index.docx"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"manuscript":{"article":"index.qmd","notebooks":[],"mecaFile":"index-meca.zip"},"quarto-internal":{"subarticles":[]},"notebook-preview-options":{"back":true},"theme":"cosmo","title-block-style":"manuscript","lightbox":"auto","title":"Sentiment Analysis with Python","authors":[{"name":"Mert Demir","affiliation":"Fondazione Eni Enrico Mattei","roles":"Research Data Scientist","corresponding":true}],"bibliography":["references.bib"],"google-scholar":true,"clear-hidden-classes":"none","remove-hidden":"all","unroll-markdown-cells":true},"extensions":{"book":{"selfContainedOutput":true}}},"jats":{"identifier":{"display-name":"JATS","target-format":"jats","base-format":"jats"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":true,"prefer-html":false,"output-divs":true,"output-ext":"xml","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"variant":"+element_citations","format-links":[{"text":"MECA Bundle","href":"index-meca.zip","icon":"archive","attr":{"data-meca-link":"true"},"order":1000}],"notebook-preserve-cells":true},"pandoc":{"standalone":true,"default-image-extension":"png","to":"jats","output-file":"index.xml"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"manuscript":{"article":"index.qmd","notebooks":[],"mecaFile":"index-meca.zip"},"quarto-internal":{"subarticles":[]},"notebook-preview-options":{"back":true},"theme":"cosmo","title-block-style":"manuscript","lightbox":"auto","title":"Sentiment Analysis with Python","authors":[{"name":"Mert Demir","affiliation":"Fondazione Eni Enrico Mattei","roles":"Research Data Scientist","corresponding":true}],"bibliography":["references.bib"],"google-scholar":true,"clear-hidden-classes":"none","remove-hidden":"all","unroll-markdown-cells":true}}},"projectFormats":["html","docx","jats"]}